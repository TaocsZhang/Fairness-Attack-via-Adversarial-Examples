{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Adversarial fairness attack on the german credit dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import math \n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "# Keras \n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "import importlib\n",
    "\n",
    "from Adverse import *\n",
    "from Metrics import *\n",
    "from prepare_data import *\n",
    "from train_model import *\n",
    "from utilis import *\n",
    "from Fairness_metrics import Fairness_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters configuration for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_name):\n",
    "    '''\n",
    "    '''\n",
    "    if dataset_name == 'credit-g':\n",
    "        df = preprocess_credit_german('credit-g')\n",
    "        config = load_dataset(df, 'credit-g', 'age', 251, 1)\n",
    "\n",
    "    elif dataset_name == 'bank':\n",
    "        df = pd.read_pickle('fair_bank_dataset.csv')\n",
    "        df = preprocess_bank(df)\n",
    "        config = load_dataset(df, 'bank', 'age', 305, 5)\n",
    "\n",
    "    elif dataset_name == 'law':\n",
    "        df = preprocess_law(frac=1, scaler=True)\n",
    "        config = load_dataset(df, 'law', 'racetxt', 505, 5)\n",
    "\n",
    "    elif dataset_name == 'compas':\n",
    "        df = pd.read_csv(\"useful-two-year.csv\")\n",
    "        df = preprocess_compas(df)\n",
    "        config = load_dataset(df, 'compas', 'race', 1005, 5)\n",
    "    elif dataset_name == 'titanic':\n",
    "        df = pd.read_pickle(\"titanic_dataset.csv\")\n",
    "        df = preprocess_titanic(df)\n",
    "        config = load_dataset(df, 'titanic', 'Sex', 305, 5)  \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_data('credit-g')\n",
    "\n",
    "df_train = config['TrainData']\n",
    "df_test = config['TestData']\n",
    "df_valid = config['ValidData']\n",
    "target = config['Target']\n",
    "feature_names = config['FeatureNames']\n",
    "sen_attribute = config['sen_attribute']\n",
    "X_train = torch.FloatTensor(df_train[feature_names].values)\n",
    "y_train = keras.utils.to_categorical(df_train[target], 2)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "D_in = X_train.size(1)\n",
    "D_out = y_train.size(1)\n",
    "H = 100\n",
    "net = GermanNet(D_in, H, D_out)\n",
    "epochs = 400\n",
    "lr = 1e-4\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> epoch 0\tLoss 0.02422\tAcc 0.45124\n",
      "> epoch 50\tLoss 0.02334\tAcc 0.68099\n",
      "> epoch 100\tLoss 0.02296\tAcc 0.72231\n",
      "> epoch 150\tLoss 0.02257\tAcc 0.78678\n",
      "> epoch 200\tLoss 0.02223\tAcc 0.82645\n",
      "> epoch 250\tLoss 0.02194\tAcc 0.86281\n",
      "> epoch 300\tLoss 0.02153\tAcc 0.89752\n",
      "> epoch 350\tLoss 0.02107\tAcc 0.93719\n",
      "test accuracy 0.668\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    preds, epoch_loss, epoch_acc = train(net, criterion, optimizer, config)\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"> epoch {:.0f}\\tLoss {:.5f}\\tAcc {:.5f}\".format(epoch, epoch_loss, epoch_acc))\n",
    "\n",
    "# Compute accuracy on the test set\n",
    "test_result = test(net, criterion, config)\n",
    "print('test accuracy', test_result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"net_\" + dataset_name)\n",
    "net = torch.load(\"net_\" + dataset_name)\n",
    "config['Model'] = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd33e70d99f546958f35635665114b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='lpf'), FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bab48d4e22b4306a27f76f8c8baba7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='df'), FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate adversarial examples\n",
    "epsilon = 0.2 \n",
    "maxiters = 500\n",
    "adv_02_500_lpf = gen_adv(config, 'lpf', dataset_name, epsilon, maxiters)\n",
    "adv_02_500_df = gen_adv(config, 'df', dataset_name, epsilon, maxiters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "list_metrics = {'SuccessRate': True,\n",
    "                'iter_means': False,\n",
    "                'iter_std': False,\n",
    "                'normdelta_median': True,\n",
    "                'normdelta_mean': True,\n",
    "                'n_std': True,\n",
    "                'weighted_median': True,\n",
    "                'weighted_mean': True,\n",
    "                'w_std': True,\n",
    "                'mean_dists_at_org': True,\n",
    "                'median_dists_at_org': False,\n",
    "                'mean_dists_at_tgt': True,\n",
    "                'mean_dists_at_org_weighted': True,\n",
    "                'mdow_std': False,\n",
    "                'median_dists_at_org_weighted': False,\n",
    "                'mean_dists_at_tgt_weighted': True,\n",
    "                'mdtw_std': False,\n",
    "                'prop_same_class_arg_org': False,\n",
    "                'prop_same_class_arg_adv': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_results(test_result, df_test, df_adv_lpf, df_adv_df, config, list_metrics, epsilon, num):\n",
    "    '''\n",
    "    get the results of individual adversarial bias, group adversarial bias, and perturbation metrics\n",
    "    '''\n",
    "    df_adv_lpf[sen_attribute] = df_test[sen_attribute]\n",
    "    df_adv_df[sen_attribute] = df_test[sen_attribute]\n",
    "\n",
    "    distance = calculate_distance(test_result[3], test_result[4])\n",
    "    lpf_result = select_adversarial_examples(df_test, df_adv_lpf, distance, 'adv', sen_attribute, num)\n",
    "    df_result = select_adversarial_examples(df_test, df_adv_df, distance, 'adv', sen_attribute, num)\n",
    "    lpf_random_result = select_adversarial_examples(df_test, df_adv_lpf, distance, 'random', sen_attribute, num)\n",
    "    df_random_result = select_adversarial_examples(df_test, df_adv_df, distance, 'random', sen_attribute, num)\n",
    "\n",
    "    lpf_mix_test = lpf_result[0]\n",
    "    df_mix_test = df_result[0]\n",
    "    lpf_random_mix_test = lpf_random_result[0]\n",
    "    df_random_mix_test = df_random_result[0]\n",
    "\n",
    "    # discrimination level of demographic parity in original test set, lpf set, and df set\n",
    "    dis_orig_test = check_discrimination(df_adv_lpf, sen_attribute, 'orig_pred')\n",
    "    print('dis of DP on the original test set:', dis_orig_test)\n",
    "\n",
    "    # the discrimination level of the proposed method in mixed lpf, mixed df, and random mixed set\n",
    "    dis_lpf_mix_test = check_discrimination(lpf_mix_test, sen_attribute, 'orig_pred')\n",
    "    print('dis of DP on the LPF test set with Proposed LPF method:', dis_lpf_mix_test)\n",
    "\n",
    "    dis_df_mix_test = check_discrimination(df_mix_test, sen_attribute, 'orig_pred')\n",
    "    print('dis of DP on the DF test set with proposed DF method:', dis_df_mix_test)\n",
    "\n",
    "    dis_lpf_random_mix_test = check_discrimination(lpf_random_mix_test, sen_attribute, 'orig_pred')\n",
    "    print('dis of DP on the LPF test set with random LPF method:', dis_lpf_random_mix_test)\n",
    "\n",
    "    dis_df_random_mix_test = check_discrimination(df_random_mix_test, sen_attribute, 'orig_pred')\n",
    "    print('dis of DP on the DF test set with random DF method:', dis_df_random_mix_test)\n",
    "    \n",
    "    result = [dis_orig_test, dis_lpf_mix_test, dis_df_mix_test, dis_lpf_random_mix_test, dis_df_random_mix_test]\n",
    "    path = 'exp_result/'\n",
    "    file_name = dataset_name + '' + str(epsilon) + ' num ' + str(num) + ' dis result'\n",
    "    full_path = os.path.join(path, file_name)\n",
    "\n",
    "    with open(full_path, 'wb') as to_write:\n",
    "        pickle.dump(result, to_write)\n",
    "    \n",
    "    \n",
    "    # selected adversarial examples\n",
    "    selected_lpf_reindex = lpf_result[1].reset_index(drop=True)\n",
    "    selected_df_reindex = df_result[1].reset_index(drop=True)\n",
    "    selected_lpf_random_reindex = lpf_random_result[1].reset_index(drop=True)\n",
    "    selected_df_random_reindex = df_random_result[1].reset_index(drop=True)\n",
    "\n",
    "    # original examples corresponding to the selected adversarial examples\n",
    "    selected_lpf_test_reindex = lpf_result[2].reset_index(drop=True)\n",
    "    selected_df_test_reindex = df_result[2].reset_index(drop=True)\n",
    "    selected_lpf_random_test_reindex = lpf_random_result[2].reset_index(drop=True)\n",
    "    selected_df_random_test_reindex = df_random_result[2].reset_index(drop=True)\n",
    "\n",
    "    ori_test_reindex = df_test.reset_index(drop=True)\n",
    "\n",
    "    config['AdvData'] = {'LowProFool': selected_lpf_reindex, 'Deepfool': selected_df_reindex, \n",
    "                         'Random_LPF': selected_lpf_random_reindex, 'Random_DF': selected_df_random_reindex}\n",
    "\n",
    "    config['TestDataset'] = {'LowProFool': selected_lpf_test_reindex, 'Deepfool': selected_df_test_reindex, \n",
    "                         'Random_LPF': selected_lpf_random_test_reindex, 'Random_DF': selected_df_random_test_reindex}\n",
    "    config['ori_test_reindex'] = ori_test_reindex\n",
    "\n",
    "    all_metrics = get_metrics(config, list_metrics)\n",
    "    all_metrics = pd.DataFrame(all_metrics, columns=['Method'] + [k for k, v in list_metrics.items() if v])\n",
    "    file_name = dataset_name + '' + str(epsilon) + ' num ' + str(num) + ' perturbation result'\n",
    "    full_path = os.path.join(path, file_name)\n",
    "    all_metrics.to_pickle(full_path)\n",
    "    return result, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dis of DP on the original test set: (-0.01664832140891581, 65, 27, 109, 49, 0.7065217391304348, 0.689873417721519)\n",
      "dis of DP on the LPF test set with Proposed LPF method: (0.39157952669235, 42, 50, 134, 24, 0.45652173913043476, 0.8481012658227848)\n",
      "dis of DP on the DF test set with proposed DF method: (0.38070996147495867, 43, 49, 134, 24, 0.4673913043478261, 0.8481012658227848)\n",
      "dis of DP on the LPF test set with random LPF method: (0.002476609796367657, 58, 34, 100, 58, 0.6304347826086957, 0.6329113924050633)\n",
      "dis of DP on the DF test set with random DF method: (0.006053935057787507, 60, 32, 104, 54, 0.6521739130434783, 0.6582278481012658)\n"
     ]
    }
   ],
   "source": [
    "num = int(0.2 * df_test.shape[0])\n",
    "result = get_results(test_result, df_test, adv_02_500_lpf, adv_02_500_df, config, list_metrics, 0.2, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>SuccessRate</th>\n",
       "      <th>normdelta_median</th>\n",
       "      <th>normdelta_mean</th>\n",
       "      <th>n_std</th>\n",
       "      <th>weighted_median</th>\n",
       "      <th>weighted_mean</th>\n",
       "      <th>w_std</th>\n",
       "      <th>mean_dists_at_org</th>\n",
       "      <th>mean_dists_at_tgt</th>\n",
       "      <th>mean_dists_at_org_weighted</th>\n",
       "      <th>mean_dists_at_tgt_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LowProFool</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.211955</td>\n",
       "      <td>0.197449</td>\n",
       "      <td>0.114948</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.023317</td>\n",
       "      <td>0.016723</td>\n",
       "      <td>0.558270</td>\n",
       "      <td>0.623987</td>\n",
       "      <td>0.102180</td>\n",
       "      <td>0.151405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deepfool</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.106596</td>\n",
       "      <td>0.108978</td>\n",
       "      <td>0.085496</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.032593</td>\n",
       "      <td>0.026229</td>\n",
       "      <td>0.558270</td>\n",
       "      <td>0.623987</td>\n",
       "      <td>0.102180</td>\n",
       "      <td>0.151405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random_LPF</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.208126</td>\n",
       "      <td>0.212629</td>\n",
       "      <td>0.113996</td>\n",
       "      <td>0.025367</td>\n",
       "      <td>0.034290</td>\n",
       "      <td>0.029792</td>\n",
       "      <td>0.673232</td>\n",
       "      <td>0.504945</td>\n",
       "      <td>0.083925</td>\n",
       "      <td>0.076118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random_DF</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.120760</td>\n",
       "      <td>0.134818</td>\n",
       "      <td>0.096815</td>\n",
       "      <td>0.039039</td>\n",
       "      <td>0.039590</td>\n",
       "      <td>0.029053</td>\n",
       "      <td>0.546718</td>\n",
       "      <td>0.788273</td>\n",
       "      <td>0.114417</td>\n",
       "      <td>0.158181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Method  SuccessRate  normdelta_median  normdelta_mean     n_std  \\\n",
       "0  LowProFool         0.96          0.211955        0.197449  0.114948   \n",
       "1    Deepfool         0.94          0.106596        0.108978  0.085496   \n",
       "2  Random_LPF         0.92          0.208126        0.212629  0.113996   \n",
       "3   Random_DF         0.92          0.120760        0.134818  0.096815   \n",
       "\n",
       "   weighted_median  weighted_mean     w_std  mean_dists_at_org  \\\n",
       "0         0.019158       0.023317  0.016723           0.558270   \n",
       "1         0.027690       0.032593  0.026229           0.558270   \n",
       "2         0.025367       0.034290  0.029792           0.673232   \n",
       "3         0.039039       0.039590  0.029053           0.546718   \n",
       "\n",
       "   mean_dists_at_tgt  mean_dists_at_org_weighted  mean_dists_at_tgt_weighted  \n",
       "0           0.623987                    0.102180                    0.151405  \n",
       "1           0.623987                    0.102180                    0.151405  \n",
       "2           0.504945                    0.083925                    0.076118  \n",
       "3           0.788273                    0.114417                    0.158181  "
      ]
     },
     "execution_count": 1355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
